---
title: "Exploration of the epigraphic text using TidyText approach"
author: "Petra Hermankova"
date: "26/10/2020"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: true
    number_sections: true
    toc_depth: 2
    df_print: paged
---

# Initial setup

## Setup of the environment:

```{r setup, echo=TRUE, message=FALSE}
Sys.setlocale("LC_ALL","English")
Sys.setenv("LANGUAGE"="EN")
#devtools::install_github("sdam-au/sdam") # loading SDAM custom package, if not working try devtools::install_github("mplex/cedhar", subdir="pkg/sdam")
#devtools::install_github("mplex/cedhar", subdir="pkg/sdam")
library(tidyverse)
library(sdam)
library(jsonlite)
library(leaflet)
library(tidytext)
```

## Loading data 
### Option 1 - with sciencedata.dk credentials
Load the dataset, if you have Sciencedata.dk credentials

```{r, echo=FALSE}
mycred_secret<- readLines("~/mysecret.txt")
```

```{r, loading data}
resp = request("EDH_text_cleaned_2020-10-09.json", path="/sharingin/648597@au.dk/SDAM_root/SDAM_data/EDH/public", method="GET", cred=mycred_secret)
```

```{r, echo=FALSE}
remove(mycred_secret)
```

### Loading data as anonymous user (no credentials needed)

Please ignore and close the pop-up window asking for username and login. The data will then download itself without login credentials.
```{r}
resp = request("EDH_text_cleaned_2020-10-09.json", path="/public/b6b6afdb969d378b70929e86e58ad975", method="GET")
```


2. Make a list and tibble from the request function
```{r}
list_json <- jsonlite::fromJSON(resp)
EDH_tibble <- as_tibble(list_json)
```

3. Display the first 6 records
```{r}
head(EDH_tibble)
```


# Tidy text analysis of the `clean_text_interpretive_word` column

## Tokenizing words, splitting on an empty space
```{r}
EDH_tokenized <- EDH_tibble %>% 
  unnest_tokens(word, clean_text_interpretive_word, token = stringr::str_split, pattern = " ") %>% 
  drop_na(word) %>%
  print()
```

## Remove pronouns and prepositions
```{r}
EDH_tokenized %>% 
  count(word, sort = TRUE) %>% 
  head(20)

# my own minimal list, for better one , see quanteda package or 
# https://github.com/aurelberra/stopwords
stop_wordLT <- tibble(word = c("ab", "ac", "ad", "adhic", "aliqui", "aliquis", "an", "ante", "apud", "at", "atque", "aut", "autem", "cum", "cur", "de", "deinde", "dum", "ego", "enim", "ergo", "es", "est", "et", "etiam", "etsi", "ex", "fio", "haud", "hic", "iam", "idem", "igitur", "ille", "in", "infra", "inter", "interim", "ipse", "is", "ita", "magis", "modo", "mox", "nam", "ne", "nec", "necque", "neque", "nisi", "non", "nos", "o", "ob", "per", "possum", "post", "pro", "quae", "quam", "quare", "qui", "quia", "quicumque", "quidem", "quilibet", "quis", "quisnam", "quisquam", "quisque", "quisquis", "quo", "quoniam", "sed", "si", "sic", "sive", "sub", "sui", "sum", "super", "suus", "tam", "tamen", "trans", "tu", "tum", "ubi", "uel", "uero", "et", "in", "i", "ii", "iii", "que", "iv", "v"))

# removing stopword list from the word list
EDH_stop <- EDH_tokenized %>% 
  anti_join(stop_wordLT, by = "word")

# removing roman numerals from the word list
library(googlesheets4)

gs4_deauth() # de-uthorized mode, no need of authentication token (if the spreadsheet is public)
numerals<- read_sheet("https://docs.google.com/spreadsheets/d/1RKRNMlSjB3yF3FHXPLhGfnLJis63300R9x65BdAKa8o/edit?usp=sharing", sheet = "stopwordlist")

EDH_stop <- EDH_stop %>% 
  anti_join(numerals, by = "word")

```

## Counting the most common words (without stopwords)
```{r, tidy=TRUE}
EDH_stop %>% 
  count(word, sort = TRUE) %>% 
  filter(n > 4000) %>% 
  mutate(word = reorder(word, n)) %>% 
  print()
```

## Number of total words on inscriptions per Roman province
```{r}
EDH_tokenized %>% 
  count(province_label_clean, word, sort = TRUE) %>% 
  group_by(province_label_clean) %>% 
  summarise(total = sum(n)) %>% 
  mutate(province_label_clean = reorder(province_label_clean, total)) -> words_total_province

head(words_total_province)
```

```{r, fig.height=08, fig.width=12}
words_total_province %>% 
  ggplot(aes(total, province_label_clean)) +
  geom_col(fill = "darkblue", width = 0.7) +
  theme_classic() +
  labs(x = "Number of words", y = "Province name", title = "Number of total words on inscriptions per Roman province", subtitle = "EDH dataset, n = 81,476 inscriptions") +
  theme_linedraw(base_size = 10) 
```

## The most common words by Roman provinces (stopwords excluded)
```{r}
EDH_stop %>% 
  count(province_label_clean, word, sort = TRUE) %>% 
  group_by(province_label_clean) %>% 
  filter(n > 500) %>%
  mutate(province_label_clean = reorder(province_label_clean, n)) %>% 
  ggplot(aes(y=province_label_clean, x=n)) +
  geom_col(aes(fill=word), width=0.7) +
  labs(x = "Number of words", y = "Province name", title = "The most common words on inscriptions per Roman province", subtitle = "EDH dataset, n = 81,476 inscriptions") +
  theme_linedraw(base_size = 10) 
  
```

## The most common words by type of an inscription (epitaph)
```{r}
EDH_stop %>% 
  count(type_of_inscription_clean, word, sort = TRUE) %>% 
  group_by(type_of_inscription_clean) %>% 
  filter(type_of_inscription_clean == "epitaph") %>% 
  filter(n > 1000) %>% 
  mutate(word = reorder(word, n)) -> words_epitaph

total_words_epitaph<- sum(words_epitaph$n)

words_epitaph %>% 
  ggplot(aes(y=word, x=n, color=n)) +
  geom_col(width=0.7) + 
  scale_color_gradient(low="blue", high="red") + 
  theme_minimal() +
  theme_linedraw(base_size = 9) +
  labs(x = "Number of words", y = "Word", title = "The most common words on epitaphs", subtitle = "n = 123,039 words")
  
```

## The most common words by type of an inscription (milestone)
```{r}
EDH_stop %>% 
  count(type_of_inscription_clean, word, sort = TRUE) %>% 
  group_by(type_of_inscription_clean) %>% 
  filter(type_of_inscription_clean == "mile-/leaguestone") %>% 
  filter(n > 100) %>% 
  mutate(word = reorder(word, n)) -> words_milestone
words_milestone

total_words_milestone <- sum(words_milestone$n)

words_milestone %>% 
  ggplot(aes(y=word, x=n, color=n)) +
  geom_col(width=0.6) + 
  scale_color_gradient(low="blue", high="red") + 
  theme_minimal() +
  theme_linedraw(base_size = 9) +
  labs(x = "Number of words", y = "Word", title = "The most common words on milestones", subtitle = "n = 24,986 words")
ggsave(filename = "../figures/EDH_milestone_common_words.png", width = 8, height = 8)
```

## The most common words on milestones per province
```{r}
EDH_stop %>% 
  filter(type_of_inscription_clean == "mile-/leaguestone") %>% 
  count(province_label_clean, word, sort = TRUE) %>% 
  group_by(province_label_clean) %>% 
  filter(n > 50) %>%
  mutate(province_label_clean = reorder(province_label_clean, n)) %>% 
  ggplot(aes(y=province_label_clean, x=n)) +
  geom_col(aes(fill=word), width=0.7) +
  labs(x = "Number of words", y = "Province name", title = "The most common words on milestones per Roman province", subtitle = "EDH dataset, n = 81,476 inscriptions") +
  theme_linedraw(base_size = 10) 
  
```

```{r, warning=FALSE}
library(wordcloud)

EDH_stop %>% 
  filter(type_of_inscription_clean == "mile-/leaguestone") %>% 
  count(province_label_clean, word, sort = TRUE) %>% 
  group_by(province_label_clean) %>% 
  filter(n > 50) %>%
  mutate(province_label_clean = reorder(province_label_clean, n)) %>% 
  with(wordcloud(word, n, max.words = 200))
```

# Frequency of words
Source: https://www.tidytextmining.com/tfidf.html
Using term frequency and inverse document frequency allows us to find words that are characteristic for one document within a collection of documents.
```{r}
insc_types_words <- EDH_stop %>% 
  count(type_of_inscription_clean, word, sort = TRUE)

total_words <- insc_types_words %>% 
  group_by(type_of_inscription_clean) %>% 
  summarize(total = sum(n))
insc_types_words <- left_join(insc_types_words, total_words)
insc_types_words
```

```{r, fig.height=10}
ggplot(insc_types_words, aes(n/total, fill = type_of_inscription_clean)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~type_of_inscription_clean, ncol = 4, scales = "free_y")
ggsave(filename = "../figures/EDH_freq_words_insc_type.png", width = 8, height = 8)
```

## Rank of words (Zip's law)
```{r}
freq_by_rank <- insc_types_words %>% 
  group_by(type_of_inscription_clean) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

freq_by_rank
```
```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = type_of_inscription_clean)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + 
  scale_x_log10() +
  scale_y_log10()
```
```{r}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
```

```{r}
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = type_of_inscription_clean)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) + 
  geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
  scale_x_log10() +
  scale_y_log10()
```
Commentary: EDH corpus uses a lower percentage of the most common words than many collections of language.


## Term frequency vs inverse document frequency

https://www.tidytextmining.com/tfidf.html
The statistic tf-idf is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites.

```{r}
insc_types_words <- insc_types_words %>%
  bind_tf_idf(word, type_of_inscription_clean, n)

insc_types_words
```

```{r}
insc_types_words %>%
  select(-total) %>%
  arrange(desc(tf_idf))
```

```{r, fig.height=8}
insc_types_words %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(type_of_inscription_clean) %>% 
  slice_head(n=10) %>% 
  ggplot(aes(word, tf_idf, fill = type_of_inscription_clean)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~type_of_inscription_clean, ncol = 4, scales = "free_y") +
  coord_flip() +
  labs(x = "word", y = "tf-idf", title = "Single words: term frequency - inverse document frequency (tf-idf) by type of inscription", subtitle = "EDH dataset, n = 81,476 inscriptions") +
  theme_linedraw(base_size = 10)
ggsave("../figures/EDH_tf_idf_insc_type.png", width = 16, height = 16)
```


# N-grams and correlations

## Bigrams without Roman numerals
```{r}
insc_bigrams <- EDH_tibble %>%
  select(clean_text_interpretive_word, type_of_inscription_clean, province_label_clean) %>% 
  mutate(clean_no_numerals = str_replace_all(clean_text_interpretive_word, numerals$word_boundaries, "")) %>% 
  unnest_tokens(bigram, clean_no_numerals, token = "ngrams", n = 2)
head(insc_bigrams)
```
```{r}
insc_bigrams %>% 
  count(bigram, sort = TRUE)
```

```{r}
bigrams_separated <- insc_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_separated %>% 
  count(word1, word2, sort = TRUE)
```
### Analysis of bi-grams

What other words occur together with the word passuum. 
```{r}
bigrams_separated %>%
  filter(word2 == "passuum") %>%
  count(type_of_inscription_clean, word1, sort = TRUE)
```

```{r}
bigrams_separated %>%
  filter(word1 == "passuum") %>%
  count(type_of_inscription_clean, word2, sort = TRUE)
```
### Frequencies in bigram
```{r}
bigram_tf_idf <- insc_bigrams%>%
  count(type_of_inscription_clean, bigram) %>%
  bind_tf_idf(bigram, type_of_inscription_clean, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf
```

```{r}
bigram_tf_idf %>%
  arrange(desc(tf_idf)) %>%
  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(type_of_inscription_clean) %>% 
  slice_head(n=10) %>%  
  ggplot(aes(bigram, tf_idf, fill = type_of_inscription_clean)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~type_of_inscription_clean, ncol = 4, scales = "free_y") +
  coord_flip() +
  labs(x = "bigram", y = "tf-idf", title = "Most important pair of words (bigrams) by inscription type", subtitle = "Epigraphic Database Heidelberg (EDH) dataset, n=81,476 inscriptions, tf-idf method") +
  theme_linedraw(base_size = 10) +
  theme(plot.title = element_text(size=40)) + 
  theme(axis.text = element_text(size = 14)) +
  theme(plot.subtitle = element_text(size=24))
ggsave("../figures/EDH_bigrams_tf_idf_insc_type.png", width = 20, height = 20)
```
### Visualising bigrams as network

```{r}
library(igraph)

bigram_graph<- bigrams_separated %>% 
  count(word1, word2, sort = TRUE) %>% 
  filter(n > 500) %>%
  graph_from_data_frame() 
bigram_graph
```

```{r}
library(ggraph)
set.seed(1000)

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
ggsave("../figures/EDH_bigrams_networks.png", width = 10, height = 10)
```

#### Another network graph
```{r}
set.seed(1000)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 4) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
ggsave("../figures/EDH_bigrams_networks_2.png", width = 10, height = 10)
```

## Tri-grams
```{r}
insc_trigram <- EDH_tibble %>%
  select(clean_text_interpretive_word, type_of_inscription_clean, province_label_clean) %>%
  unnest_tokens(trigram, clean_text_interpretive_word, token = "ngrams", n = 3) %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
  count(word1, word2, word3, sort = TRUE)
insc_trigram

```


```{r}

trigram_graph<- insc_trigram %>% 
  filter(n > 300) %>%
  graph_from_data_frame() 

trigram_graph

set.seed(1000)

b <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(trigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = b, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 4) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
ggsave("../figures/EDH_trigrams_networks_2.png", width = 10, height = 10)
```

## Counting and correlating pairs of words with the widyr package
```{r}
library(widyr)

# count words co-occuring within sections
word_pairs<- EDH_stop %>% 
  pairwise_count(word, id, sort = TRUE)

word_pairs
```

```{r}
word_pairs %>%
  filter(item1 == "votum")
```

###  Pairwise correlation
Correlation among words, which indicates how often they appear together relative to how often they appear separately.
```{r}
word_cors <- EDH_tokenized %>%
  group_by(word) %>%
  filter(n() >= 100) %>%
  pairwise_cor(word, id, sort = TRUE)

word_cors
```
```{r}
word_cors %>%
  filter(item1 == "votum")
```
#### Correlation of word related vocabulary

##### Milestones
```{r}
word_cors %>%
  filter(item1 %in% c("milia", "passuum", "via", "viator")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  #ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity", aes(fill=correlation), width=0.7) + 
  facet_wrap(~ item1, scales = "free_y") +
  theme_minimal() +
  coord_flip() +
  labs(y = "Correlation of word-pairs", x = "Word", title = "The most common word-pair correlations on inscriptions", subtitle = "EDH dataset, n = 81,476 inscriptions") 
ggsave("../figures/EDH_word_pair_corr_milestones.png", width = 10, height = 10)
```

##### Dis Manibus

```{r}
word_cors %>%
  filter(item1 %in% c("dis", "manibus", "sacrum")) %>%
  group_by(item1) %>%
  top_n(10) %>%
  #ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity", aes(fill=correlation), width=0.7) + 
  facet_wrap(~ item1, scales = "free_y") +
  theme_minimal() +
  coord_flip() +
  labs(y = "Correlation of word-pairs", x = "Word", title = "The most common word-pair correlations for the formula Dis Manibus Sacrum", subtitle = "EDH dataset, n = 81,476 inscriptions") 
ggsave("../figures/EDH_word_pair_corr_dis_manibus.png", width = 10, height = 10)
```



#### Visualisation of correlations 

Correlation pairs with 3000 and more times frequency
```{r}
word_cors_3000 <- EDH_tokenized %>%
  group_by(word) %>%
  filter(n() >= 3000) %>%
  pairwise_cor(word, id, sort = TRUE)

set.seed(1000)

word_cors_3000 %>%
  filter(correlation > .15) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
ggsave("../figures/EDH_word_pair_corr_3000.png", width = 10, height = 10)
```
Correlation pairs with 1000 and more times frequency
```{r}
word_cors_1000 <- EDH_tokenized %>%
  group_by(word) %>%
  filter(n() >= 1000) %>%
  pairwise_cor(word, id, sort = TRUE)

set.seed(1000)

word_cors_1000 %>%
  filter(correlation > .15) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "yellow", size = 3) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
ggsave("../figures/EDH_word_pair_corr_1000.png", width = 10, height = 10)
```

Different visualisation of co-ocurring words
```{r}

EDH_word_pairs <- EDH_tokenized %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE)

set.seed(1000)


EDH_word_pairs %>%
  filter(n >= 1000) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 2) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.4, "lines")) +
  theme_void()
ggsave("../figures/EDH_word_pair_corr_1000_2.png", width = 10, height = 10)
```



# Converting to non-tidy format (matrix)
```{r}
library(tm)
EDH_dtm <- EDH_tokenized %>%
  count(type_of_inscription_clean, word) %>%
  cast_dtm(type_of_inscription_clean, word, n)
EDH_dtm
```

```{r}
library(quanteda)
EDH_dfm <- EDH_tokenized %>%
  count(type_of_inscription_clean, word) %>%
  cast_dfm(type_of_inscription_clean, word, n)
EDH_dfm
```

## Exploration of matrix
```{r}
# how many words has milestone
sum(EDH_dfm["mile-/leaguestone",])
max(EDH_dfm["mile-/leaguestone",])
milestone <- EDH_dfm["mile-/leaguestone",]
```

### Topic modelling




